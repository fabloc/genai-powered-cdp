[GOOGLE_CLOUD]
project_id =
region =
dataproject_id =
auth_user = admin@fabienlocquet.altostrat.com

[TABLES]
# TABLES contain the tables to be used for SQL generation.
# Enter an empty table list when all tables in the dataset should be used
source_type = BigQuery
tables = ["hll_user_aggregates", "products_aggregates"]
# tables = ["hll_user_aggregates"]
# BQ Schema (DATASET) where tables leave
schema = publisher_1_dataset
user_dataset = ${GOOGLE_CLOUD:dataproject_id}.${schema}

[EXECUTION]
# Execution Parameters
sql_validation = ALL
inject_one_error = False
sql_max_error_retry = 3
semantic_validation = True
auto_add_knowngood_sql = False
execute_final_sql = True
display_bq_max_results = 10000

[ANALYTICS]
# Analytics Warehouse
enable_analytics = False
dataset_name = nl2sql
dataset_location = europe-west1
log_table_name = query_logs

[ML_MODELS]
fast_sql_generation_model_id = gemini-pro
fine_sql_generation_model_id = text-unicorn
sql_correction_model_id = text-unicorn
validation_model_id = text-unicorn
embeddings_model = textembedding-gecko@003
models_timeout = 20

[VECTOR_DATABASE]
update_db_at_startup = True
database_password =
instance_name = pgvector-db
database_name =
database_user =
num_table_matches = 5
num_column_matches = 20
similarity_threshold = 0.1
num_sql_matches=3

# @markdown Create an HNSW index
m =  24
ef_construction = 100
operator =  vector_cosine_ops  # ["vector_cosine_ops", "vector_l2_ops", "vector_ip_ops"]