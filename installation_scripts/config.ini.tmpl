[GOOGLE_CLOUD]
project_id =
region =
auth_user =

[TABLES]
# TABLES contain the tables to be used for SQL generation.
# Enter an empty table list when all tables in the dataset should be used
source_type = BigQuery
# BQ Project and Dataset where tables live
project_id_data =
dataset_id =
tables = ["user_aggregates", "product_aggregates"]
user_dataset = ${project_id_data}.${dataset_id}

[EXECUTION]
# Execution Parameters
sql_validation = ALL
inject_one_error = False
sql_max_error_retry = 3
semantic_validation = True
auto_add_knowngood_sql = False
execute_final_sql = True
display_bq_max_results = 10000

[ANALYTICS]
# Analytics Warehouse
enable_analytics = False
dataset_name = nl2sql
dataset_location = europe-west1
log_table_name = query_logs

[ML_MODELS]
fast_sql_generation_model_id = gemini-pro
fine_sql_generation_model_id = text-unicorn
sql_correction_model_id = text-unicorn
validation_model_id = text-unicorn
embeddings_model = textembedding-gecko@003
models_timeout = 20

[VECTOR_DATABASE]
update_db_at_startup = True
database_password =
instance_name = pgvector-db
sql_ip_type = PRIVATE
database_name =
database_user =
num_table_matches = 5
num_column_matches = 20
similarity_threshold = 0.1
num_sql_matches=3

# @markdown Create an HNSW index
m =  24
ef_construction = 100
operator =  vector_cosine_ops