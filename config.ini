[GOOGLE_CLOUD]
project_id = cdp-demo-flocquet
region = europe-west1
dataproject_id = cdp-demo-flocquet
auth_user = admin@fabienlocquet.altostrat.com

[TABLES]
# TABLES contain the tables to be used for SQL generation.
# Enter an empty table list when all tables in the dataset should be used
source_type = BigQuery
tables = ["hll_user_aggregates", "products_aggregates"]
# tables = ["hll_user_aggregates"]
# BQ Schema (DATASET) where tables leave
schema = publisher_1_dataset
user_dataset = ${GOOGLE_CLOUD:dataproject_id}.${schema}

[EXECUTION]
# Execution Parameters
sql_validation = ALL
inject_one_error = False
sql_max_error_retry = 3
sql_max_explanation_retry = 3
auto_add_knowngood_sql = False
execute_final_sql = True

[ANALYTICS]
# Analytics Warehouse
enable_analytics = False
dataset_name = nl2sql
dataset_location = europe-west1
log_table_name = query_logs

[ML_MODELS]
#sql_generation_model_id = gemini-pro
sql_generation_model_id = text-unicorn
sql_correction_model_id = gemini-pro
validation_model_id = text-unicorn
embeddings_model = textembedding-gecko@003
models_timeout = 20

[VECTOR_DATABASE]
update_db_at_startup = True
database_password = hr_tutorial
instance_name = pg15-nl2sql-pgvector
database_name = nl2sql-admin
database_user = nl2sql-admin
num_table_matches = 5
num_column_matches = 20
similarity_threshold = 0.1
num_sql_matches=3

# @markdown Create an HNSW index
m =  24
ef_construction = 100
operator =  vector_cosine_ops  # ["vector_cosine_ops", "vector_l2_ops", "vector_ip_ops"]